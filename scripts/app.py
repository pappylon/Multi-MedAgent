import streamlit as st
import os
import sys
from dotenv import load_dotenv
from pathlib import Path

# --------------------------------
# è·¯å¾„è®¾ç½®
# --------------------------------
BASE_DIR = Path(__file__).resolve().parent.parent
SRC_DIR = BASE_DIR / "src"
sys.path.insert(0, str(SRC_DIR))


from rag.engine import GeminiRAGEngine

# --------------------------------
# åŠ è½½ç¯å¢ƒå˜é‡
# --------------------------------
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# --------------------------------
# é¡µé¢é…ç½®
# --------------------------------
st.set_page_config(page_title="Medical AI Agent (Local)", page_icon="ğŸ¥")
st.title("ğŸ¥ Medical AI Assistant")
# âœ… æ”¹åŠ¨ 2: æ›´æ–°å‰¯æ ‡é¢˜ï¼Œå¼ºè°ƒä½¿ç”¨äº†å¾®è°ƒæ¨¡å‹
st.caption("ğŸš€ Powered by **Local Fine-tuned Model** (Llama-3) & RAG Technology")

# --------------------------------
# åˆå§‹åŒ–å¼•æ“ (å¸¦ç¼“å­˜)
# --------------------------------
@st.cache_resource
def get_engine():
    # æ˜¾ç¤ºä¸€ä¸ªåŠ è½½è½¬åœˆåœˆï¼Œå› ä¸ºæœ¬åœ°åŠ è½½æ¯”è¾ƒæ…¢
    with st.spinner("æ­£åœ¨åŠ è½½æœ¬åœ°å¾®è°ƒæ¨¡å‹ (çº¦éœ€ 1-2 åˆ†é’Ÿï¼Œè¯·è€å¿ƒç­‰å¾…)..."):
        try:
            # âœ… æ”¹åŠ¨ 3: å®ä¾‹åŒ–æœ¬åœ°å¼•æ“
            return GeminiRAGEngine(k=3)
        except Exception as e:
            st.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return None

# æ‰§è¡ŒåŠ è½½
engine = get_engine()

# --------------------------------
# Session State èŠå¤©å†å²
# --------------------------------
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# --------------------------------
# å¤„ç†ç”¨æˆ·è¾“å…¥
# --------------------------------
if prompt := st.chat_input("è¯·æè¿°æ‚¨çš„ç—‡çŠ¶æˆ–é—®é¢˜..."):
    # 1. æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 2. è°ƒç”¨ AI
    if engine:
        with st.chat_message("assistant"):
            placeholder = st.empty()
            # æç¤ºè¯­æ”¹ä¸€ä¸‹
            placeholder.markdown("â³ *Local Model is thinking...*")

            try:
                # è½¬æ¢å†å²æ ¼å¼
                history_for_engine = [
                    ("User" if m["role"] == "user" else "AI", m["content"])
                    for m in st.session_state.messages[:-1]
                ]

                # è·å–å›ç­”
                response = engine.answer_question(prompt, history_for_engine)

                # æ˜¾ç¤ºå¹¶ä¿å­˜
                placeholder.markdown(response)
                st.session_state.messages.append(
                    {"role": "assistant", "content": response}
                )

            except Exception as e:
                placeholder.error(f"âŒ è¿è¡Œé”™è¯¯ï¼š{e}")
    else:
        st.error("âš ï¸ å¼•æ“æœªåˆå§‹åŒ–ï¼Œæ— æ³•å›ç­”ã€‚è¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„ã€‚")