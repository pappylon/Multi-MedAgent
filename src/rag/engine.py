import sys
import os
from langchain_core.prompts import PromptTemplate
from src.rag.loader import VectorDBLoader
from src.rag.config import MEDICAL_PROMPT_TEMPLATE

current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.abspath(os.path.join(current_dir, "../../"))
fine_tune_dir = os.path.join(project_root, "fine-tune")
if fine_tune_dir not in sys.path:
    sys.path.append(fine_tune_dir)
    print(f"âœ… å·²æ·»åŠ æ¨¡å‹è·¯å¾„: {fine_tune_dir}")

try:
    from inference import load_local_model, generate_local_response
except ImportError:
    print("âš ï¸ æ— æ³•å¯¼å…¥ inference.py")

class LocalRAGEngine:
    def __init__(self, k: int = 3):
        # 1. RAG æ£€ç´¢éƒ¨åˆ†
        print("ğŸ” åˆå§‹åŒ–æ£€ç´¢å™¨...")
        loader = VectorDBLoader(k=k)
        self.retriever = loader.load_db()

        # 2. åŠ è½½æ¨¡å‹
        # model, tokenizer, device ä¸‰ä¸ªå˜é‡éƒ½è¦æ¥ä½
        self.model, self.tokenizer, self.device = load_local_model()

        # 3. Prompt æ¨¡æ¿
        self.prompt = PromptTemplate(
            template=MEDICAL_PROMPT_TEMPLATE,
            input_variables=["context", "chat_history", "question"]
        )

    def answer_question(self, question: str, chat_history: list = None) -> str:
        if not self.model:
            return "âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•å›ç­”ã€‚"

        # 1. æ£€ç´¢
        print(f"ğŸ” [RAG] æ­£åœ¨æ£€ç´¢: {question}")
        docs = self.retriever.invoke(question)
        context_text = "\n".join([d.page_content for d in docs])

        # 2. å†å²è®°å½• (å–æœ€è¿‘2è½®)
        history_text = ""
        if chat_history:
            for role, text in chat_history[-2:]:
                history_text += f"{role}: {text}\n"

        # 3. ç»„è£…ç¬¦åˆè®­ç»ƒæ ¼å¼çš„ Prompt
        full_prompt = self.prompt.format(
            context=context_text,
            chat_history=history_text,
            question=question
        )

        # 4. ç”Ÿæˆ
        print("ğŸ§  [Local Model] æ­£åœ¨ç”Ÿæˆå›ç­”...")
        response = generate_local_response(self.model, self.tokenizer, self.device, full_prompt)
        
        return response